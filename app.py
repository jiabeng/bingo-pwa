#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os, sys, json, csv, sqlite3, threading, time, re
from datetime import datetime, date, timedelta
from collections import Counter
from flask import Flask, jsonify, render_template, send_from_directory, request
import requests
from bs4 import BeautifulSoup

# â€”â€” åœ¨ Render ä¸Šç•¥éä¸å®Œæ•´æ†‘è­‰éˆçš„é©—è­‰è­¦å‘Šï¼ˆå°å½© API/å®˜ç¶² HTMLï¼‰â€”â€”
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ---- åŸºæœ¬è¨­å®š ----
API_URL  = os.getenv("BINGO_API_URL", "https://api.taiwanlottery.com/TLCAPIWeB/Lottery/LatestBingoResult")
DB_PATH  = os.getenv("DB_PATH",  os.path.join("data", "bingo.db"))
CSV_PATH = os.getenv("CSV_PATH", os.path.join("data", "bingo_super.csv"))
TOP_K    = int(os.getenv("TOP_K", "10"))
MIN_TODAY_ROWS_FOR_RECO = int(os.getenv("MIN_TODAY_ROWS_FOR_RECO", "15"))

os.makedirs("data", exist_ok=True)
app = Flask(__name__)

# ---- DB ----
SCHEMA_SQL = (
    "CREATE TABLE IF NOT EXISTS bingo_super ("
    " draw_term INTEGER PRIMARY KEY,"
    " draw_time TEXT NOT NULL,"
    " super_number INTEGER NOT NULL,"
    " open_order TEXT NOT NULL,"
    " high_low TEXT,"
    " odd_even TEXT,"
    " fetched_at TEXT NOT NULL)"
)
def db_conn():
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.execute(SCHEMA_SQL)
    return conn
CONN = db_conn()

def append_csv(row: dict):
    exists = os.path.isfile(CSV_PATH)
    with open(CSV_PATH, 'a', newline='', encoding='utf-8') as f:
        w = csv.DictWriter(f, fieldnames=[
            "draw_term","draw_time","super_number","open_order","high_low","odd_even","fetched_at"
        ])
        if not exists: w.writeheader()
        w.writerow({
            "draw_term": row["draw_term"],
            "draw_time": row["draw_time"],
            "super_number": row["super_number"],
            "open_order": ",".join(row["open_order"]),
            "high_low": row["high_low"],
            "odd_even": row["odd_even"],
            "fetched_at": row["fetched_at"],
        })

def upsert_row(row: dict):
    """å–®ç­†ï¼šåŒä¸€æœŸå°±è¦†å¯«ï¼ˆç¢ºä¿æœ€æ–°è³‡æ–™ï¼‰ï¼Œä¸åŒæœŸæœƒæ–°å¢ã€‚"""
    cur = CONN.cursor()
    cur.execute(
        "INSERT OR REPLACE INTO bingo_super(draw_term, draw_time, super_number, open_order, high_low, odd_even, fetched_at)"
        " VALUES (?, ?, ?, ?, ?, ?, ?)",
        (
            row["draw_term"], row["draw_time"], row["super_number"],
            json.dumps(row["open_order"], ensure_ascii=False),
            row.get("high_low"), row.get("odd_even"), row["fetched_at"]
        )
    )
    CONN.commit()

# ---- æ“·å–å®˜ç¶²æœ€æ–°ä¸€æœŸ ----
def fetch_latest():
    # Render å°å°å½© API æ†‘è­‰éˆåš´æ ¼ï¼šåŠ  verify=False ä»¥é€šé
    r = requests.get(API_URL, timeout=10, verify=False)
    r.raise_for_status()
    data = r.json()
    post = data["content"]["lotteryBingoLatestPost"]
    return {
        "draw_term": int(post["drawTerm"]),
        "draw_time": post["dDate"],
        "open_order": post["openShowOrder"],
        "super_number": int(post["prizeNum"]["bullEye"]),
        "high_low": post["prizeNum"].get("highLow"),
        "odd_even": post["prizeNum"].get("oddEven"),
        "fetched_at": datetime.now().isoformat(timespec='seconds')
    }

# ---- æ¯é€¢æ•´ 5 åˆ†é˜ï¼ˆ07:00ã€07:05ã€â€¦ï¼‰çš„ç¡çœ è¨ˆç®— ----
def seconds_until_next_five_minute():
    now = datetime.now()
    current_block = (now.minute // 5) * 5
    next_block = current_block + 5
    if next_block >= 60:
        next_time = (now + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
    else:
        next_time = now.replace(minute=next_block, second=0, microsecond=0)
    return (next_time - now).total_seconds()

# ---- èƒŒæ™¯ï¼šæ¯æ•´ 5 åˆ†é˜æŠ“ã€Œæœ€æ–°ä¸€æœŸã€ ----
def polling_loop():
    while True:
        try:
            latest = fetch_latest()
            upsert_row(latest)
            append_csv(latest)
        except Exception as e:
            print("[WARN] fetch failure:", e, file=sys.stderr)
        # å°é½Šåˆ°ä¸‹ä¸€å€‹æ•´ 5 åˆ†é˜
        sleep_s = max(1, int(seconds_until_next_five_minute()))
        time.sleep(sleep_s)

threading.Thread(target=polling_loop, daemon=True).start()

# ---- HTML è§£æï¼šæŠ“å–ä»Šå¤©æ‰€æœ‰å·²é–‹çæœŸæ•¸ï¼ˆå®˜ç¶²å…¬é–‹é é¢ï¼‰----
def parse_today_from_official_html(debug_save=True):
    """
    å¾å°å½© Bingo Bingo å®˜æ–¹ä»Šæ—¥é é¢æŠ“å–ã€ä»Šå¤©æ‰€æœ‰å·²é–‹çæœŸåˆ¥ã€ã€‚
    å›å‚³ list[dict]ï¼š
      { draw_term:int, draw_time:strISO(åªä¿ç•¶æ—¥), open_order:list[str], super_number:int, high_low, odd_even }
    ç­–ç•¥ï¼š
      1) å˜—è©¦å¤šå€‹å€™é¸ URLï¼ˆå®˜ç¶²è‹¥èª¿æ•´è·¯å¾‘ï¼Œä»»ä¸€å¯ç”¨å³å¯ï¼‰
      2) å…ˆç”¨è¼ƒå¯¬é¬†çš„ selector æ‰¾å¤§å®¹å™¨ï¼Œå†ä»¥ regex å°±è¿‘æŠ½æœŸåˆ¥+20é¡†çƒ
      3) é€€è€Œæ±‚å…¶æ¬¡ï¼šå…¨é æ–‡å­—å›æƒï¼ˆglobal regexï¼‰
      4) å†é€€ï¼šæƒæ <script> å…§çš„ JSONï¼ˆè‹¥é é¢æ˜¯å‰ç«¯æ¡†æ¶æ¸²æŸ“ï¼Œå¸¸æœ‰åµŒå…¥è³‡æ–™ï¼‰
      5) å¤±æ•—æ™‚æœƒæŠŠ HTML å­˜åˆ° data/last_today.html ä»¥ä¾¿ä¹‹å¾Œèª¿æ•´ selector
    """
    candidate_urls = [
        "https://www.taiwanlottery.com/lottery/Lotto/BingoBingo",
        # æ—¥å¾Œè‹¥å®˜ç¶²æä¾›æ—¥æœŸåƒæ•¸ï¼Œå¯åœ¨æ­¤è£œä¸Šè®Šé«”
        # f"https://www.taiwanlottery.com/lottery/Lotto/BingoBingo?Date={date.today().isoformat()}",
    ]
    ua = {"User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome Safari"}

    html = None
    used_url = None
    for url in candidate_urls:
        try:
            res = requests.get(url, headers=ua, timeout=15, verify=False)
            if res.status_code == 200 and len(res.text) > 1500:
                html = res.text
                used_url = url
                break
        except Exception as e:
            print("[WARN] fetch official html failed:", e, file=sys.stderr)

    if not html:
        return []

    # é™¤éŒ¯ï¼šæŠŠåŸå§‹ HTML å­˜ä¸€ä»½ï¼Œæ–¹ä¾¿å¿…è¦æ™‚æª¢è¦–é é¢å¯¦éš›çµæ§‹
    if debug_save:
        try:
            os.makedirs("data", exist_ok=True)
            with open(os.path.join("data", "last_today.html"), "w", encoding="utf-8") as f:
                f.write(html)
        except Exception as e:
            print("[WARN] save last_today.html fail:", e, file=sys.stderr)

    soup = BeautifulSoup(html, "html.parser")

    # æ­£å‰‡ï¼šæœŸåˆ¥ï¼ˆ8~12ä½æ•¸ï¼‰èˆ‡ 20 é¡†çƒ
    term_re = re.compile(r"(?:ç¬¬)?(\d{8,12})\s*æœŸ")
    # å…è¨±ã€Œæ•¸å­— + åˆ†éš”ç¬¦ã€é€£çºŒ19æ¬¡ï¼Œæœ€å¾Œä¸€é¡†å†æ¥ä¸€å€‹æ•¸å­—ï¼ˆç¸½å…±20é¡†ï¼‰
    nums_re = re.compile(r"(?:(?:^|\D)(\d{1,2})(?!\d)(?:(?:\s|,|ã€|ï¼Œ|ï¼|ãƒ»|:|ï¼›|/|-))+){19}(\d{1,2})(?!\d)")

    def z2(n: str) -> str:
        return str(int(n)).zfill(2)

    rows, seen = [], set()

    # ---------- ç­–ç•¥ 1ï¼šåœ¨å¯èƒ½çš„å®¹å™¨è£¡åšã€Œé„°è¿‘æŠ½å–ã€ ----------
    containers = []
    for sel in [
        '[id*="today"]', '[class*="today"]',
        '[id*="bingo"]', '[class*="bingo"]',
        'main', 'section', 'article', 'table', 'div'
    ]:
        containers.extend(soup.select(sel))
    containers = [c for c in containers if c.get_text(strip=True) and len(c.get_text()) > 500]

    for cont in containers:
        text = cont.get_text(" ", strip=True)
        for m in term_re.finditer(text):
            term = int(m.group(1))
            if term in seen:
                continue
            start = max(0, m.start() - 320)
            end   = min(len(text), m.end() + 320)
            window = text[start:end]
            mnum = nums_re.search(window)
            if not mnum:
                continue
            raw = re.findall(r"\d{1,2}", mnum.group(0))
            if len(raw) != 20:
                continue
            open_order = [z2(x) for x in raw]
            super_n = int(open_order[-1])
            draw_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).isoformat()
            rows.append({
                "draw_term": term,
                "draw_time": draw_time,
                "open_order": open_order,
                "super_number": super_n,
                "high_low": None,
                "odd_even": None,
            })
            seen.add(term)

    # ---------- ç­–ç•¥ 2ï¼šæ•´é æ–‡å­—å›æƒï¼ˆå®¹å™¨ç­–ç•¥æŠ“ä¸åˆ°æ™‚ï¼‰ ----------
    if not rows:
        full_text = soup.get_text(" ", strip=True)
        for m in term_re.finditer(full_text):
            term = int(m.group(1))
            if term in seen:
                continue
            start = max(0, m.start() - 360)
            end   = min(len(full_text), m.end() + 360)
            window = full_text[start:end]
            mnum = nums_re.search(window)
            if not mnum:
                continue
            raw = re.findall(r"\d{1,2}", mnum.group(0))
            if len(raw) != 20:
                continue
            open_order = [z2(x) for x in raw]
            super_n = int(open_order[-1])
            draw_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).isoformat()
            rows.append({
                "draw_term": term,
                "draw_time": draw_time,
                "open_order": open_order,
                "super_number": super_n,
                "high_low": None,
                "odd_even": None,
            })
            seen.add(term)

    # ---------- ç­–ç•¥ 3ï¼šæƒæ <script> å…§å¯èƒ½åµŒå…¥çš„ JSON ----------
    if not rows:
        scripts = soup.find_all("script")
        for sc in scripts:
            txt = sc.string or sc.get_text() or ""
            if not txt or len(txt) < 200:
                continue
            # æŠ“å‡ºç–‘ä¼¼ã€Œ20é¡†çƒé™£åˆ—ã€çš„ JSON ç‰‡æ®µ
            # ä¾‹å¦‚: "openNumbers":[12,34,...,20å€‹] æˆ– [ {numbers:[...20å€‹...]}, ...]
            # é€™è£¡å…ˆæŠ“ã€Œä¸€æ®µå…§å« 20 å€‹ 1~80 çš„æ•¸å­—ã€çš„åˆ—è¡¨ä½œç‚ºå€™é¸
            arrs = re.findall(r"\[(?:\s*\d{1,2}\s*,){19}\s*\d{1,2}\s*\]", txt)
            for arr in arrs:
                nums = re.findall(r"\d{1,2}", arr)
                if len(nums) != 20:
                    continue
                # å˜—è©¦åœ¨åŒä¸€æ®µ script é™„è¿‘æ‰¾æœŸåˆ¥
                # å¾€å‰å¾Œå„æƒä¸€äº›å­—å…ƒ
                pos = txt.find(arr)
                start = max(0, pos - 400)
                end   = min(len(txt), pos + 400)
                win   = txt[start:end]
                mterm = term_re.search(win)
                if not mterm:
                    continue
                term = int(mterm.group(1))
                if term in seen:
                    continue
                open_order = [z2(x) for x in nums]
                super_n = int(open_order[-1])
                draw_time = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0).isoformat()
                rows.append({
                    "draw_term": term,
                    "draw_time": draw_time,
                    "open_order": open_order,
                    "super_number": super_n,
                    "high_low": None,
                    "odd_even": None,
                })
                seen.add(term)

    # å»é‡å¾Œä¾æœŸåˆ¥æ’åºï¼ˆèˆŠâ†’æ–°ï¼‰
    rows = sorted({r["draw_term"]: r for r in rows}.values(), key=lambda x: x["draw_term"])
    print(f"[BACKFILL SOURCE] url={used_url} parsed={len(rows)}", file=sys.stderr)
    return rows

def upsert_many(rows: list[dict]) -> int:
    """æ‰¹æ¬¡å¯«å…¥ä»Šå¤©å¤šæœŸï¼Œä½¿ç”¨ INSERT OR IGNORE ç¢ºä¿ä¸é‡è¦†ã€‚"""
    cur = CONN.cursor()
    inserted = 0
    for r in rows:
        try:
            cur.execute(
                "INSERT OR IGNORE INTO bingo_super(draw_term, draw_time, super_number, open_order, high_low, odd_even, fetched_at) "
                "VALUES (?, ?, ?, ?, ?, ?, ?)",
                (
                    r["draw_term"],
                    r["draw_time"],
                    r["super_number"],
                    json.dumps(r["open_order"], ensure_ascii=False),
                    r.get("high_low"),
                    r.get("odd_even"),
                    datetime.now().isoformat(timespec='seconds')
                )
            )
            inserted += cur.rowcount  # 1 or 0
        except Exception as e:
            print("[WARN] insert fail:", e, file=sys.stderr)
    CONN.commit()
    return inserted

def backfill_today_once() -> dict:
    """æŠ“å–å®˜æ–¹ HTML â†’ è§£æ â†’ å¯«å…¥ DBï¼Œå›å‚³æ’å…¥ç­†æ•¸èˆ‡è§£ææ•¸"""
    rows = parse_today_from_official_html()
    if not rows:
        return {"ok": False, "inserted": 0, "parsed": 0}
    inserted = upsert_many(rows)
    return {"ok": True, "inserted": inserted, "parsed": len(rows)}

# ---- èƒŒæ™¯ï¼šæ¯ 30 åˆ†é˜è‡ªå‹•è£œé½Šä¸€æ¬¡ä»Šå¤©è³‡æ–™ ----
def backfill_scheduler_loop():
    while True:
        try:
            info = backfill_today_once()
            print("[BACKFILL]", info, file=sys.stderr)
        except Exception as e:
            print("[BACKFILL ERR]", e, file=sys.stderr)
        time.sleep(30 * 60)  # 30 åˆ†é˜å¾Œå†è©¦

threading.Thread(target=backfill_scheduler_loop, daemon=True).start()

# ---- ç•¶æ—¥çµ±è¨ˆ + æ¨è–¦ ----
def parse_dt(dt_str: str) -> datetime:
    try:
        return datetime.fromisoformat(dt_str)
    except Exception:
        return datetime.strptime(dt_str.replace('Z',''), "%Y-%m-%dT%H:%M:%S")

def query_today_rows():
    today = date.today()
    cur = CONN.cursor()
    cur.execute("SELECT draw_term, draw_time, super_number, open_order FROM bingo_super ORDER BY draw_term ASC")
    out = []
    for term, dtime, sn, ojson in cur.fetchall():
        dt = parse_dt(dtime)
        if dt.date() == today:
            out.append({
                "draw_term": term,
                "draw_time": dt.isoformat(),
                "super_number": int(sn),
                "open_order": json.loads(ojson) if isinstance(ojson, str) else ojson,
            })
    return out

def recency_unique(seq, take=20):
    last = list(seq)[-take:]
    seen, ordered = set(), []
    for n in reversed(last):    # æ–°â†’èˆŠ å»é‡
        if n not in seen:
            ordered.append(n); seen.add(n)
    return ordered

def recommend_numbers(today_supers, freq_top):
    if len(today_supers) >= MIN_TODAY_ROWS_FOR_RECO and freq_top:
        base = [n for (n, _) in freq_top]
        return {
            "pick1": base[:1],
            "pick3": base[:3] if len(base)>=3 else base,
            "pick5": base[:5] if len(base)>=5 else base,
            "rationale": "ä½¿ç”¨ã€ä»Šæ—¥ç†±åº¦æ’è¡Œã€åšç­‰é…åˆ†æ•£ã€‚"
        }
    # ä»Šæ—¥æ¨£æœ¬ä¸è¶³ â†’ æ··åˆ ä»Šæ—¥Top + è¿‘20æœŸè¼ªæ›¿å‰æ®µ
    cur = CONN.cursor()
    cur.execute("SELECT super_number FROM bingo_super ORDER BY draw_term ASC")
    all_supers = [r[0] for r in cur.fetchall()]
    today_top = [n for (n, _) in Counter(today_supers).most_common(2)]
    rec_seq = recency_unique(all_supers[-50:], take=20)
    pool = []
    for n in today_top + rec_seq[:8]:
        if n not in pool: pool.append(n)
    while len(pool) < 5 and rec_seq:
        x = rec_seq.pop(0)
        if x not in pool: pool.append(x)
    return {
        "pick1": pool[:1],
        "pick3": pool[:3],
        "pick5": pool[:5],
        "rationale": "ä»Šæ—¥æ¨£æœ¬ä¸è¶³ï¼šæ··åˆã€ä»Šæ—¥ç†±åº¦ã€+ã€è¿‘20æœŸè¼ªæ›¿å‰æ®µã€ã€‚"
    }

# ---- Routes ----
@app.get("/")
def home():
    return render_template("index.html")

@app.get("/api/ping")
def ping():
    return jsonify({"ok": True, "time": datetime.now().isoformat()})

@app.get("/api/latest")
def latest():
    cur = CONN.cursor()
    cur.execute("SELECT draw_term, draw_time, super_number, open_order, high_low, odd_even, fetched_at "
                "FROM bingo_super ORDER BY draw_term DESC LIMIT 1")
    row = cur.fetchone()
    if not row: return jsonify({"ok": False, "message": "no data"})
    term, dtime, super_n, ojson, hl, oe, ft = row
    return jsonify({
        "ok": True,
        "draw_term": term,
        "draw_time": dtime,
        "super_number": super_n,
        "open_order": json.loads(ojson),
        "high_low": hl,
        "odd_even": oe,
        "fetched_at": ft
    })

# ğŸ”˜ ç«‹å³æ›´æ–°ï¼ˆåªæŠ“æœ€æ–°ä¸€æœŸï¼‰
@app.post("/api/force-update")
def force_update():
    try:
        latest = fetch_latest()
        upsert_row(latest)
        append_csv(latest)
        return jsonify({"ok": True, "latest": latest})
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

# ğŸ“… ä¸€éµè£œé½Šä»Šå¤©æ‰€æœ‰è³‡æ–™ï¼ˆè§£æå®˜ç¶² HTMLï¼‰
@app.post("/api/fetch-today-full")
def api_fetch_today_full():
    info = backfill_today_once()
    return jsonify(info)

@app.get("/api/today-count")
def api_today_count():
    rows = query_today_rows()
    return jsonify({"ok": True, "today_count": len(rows)})

@app.get("/api/today")
def today_api():
    rows = query_today_rows()
    supers = [r["super_number"] for r in rows]
    freq_top = Counter(supers).most_common(TOP_K) if supers else []
    rec_u = recency_unique(supers, take=20) if supers else []
    reco = recommend_numbers(supers, freq_top) if supers else {"pick1":[], "pick3":[], "pick5":[], "rationale":"å°šç„¡è³‡æ–™"}
    return jsonify({
        "ok": True,
        "today_count": len(rows),
        "latest": rows[-1] if rows else None,
        "freq_top": [{"number":n, "count":c} for (n,c) in freq_top],
        "last20": supers[-20:],
        "recency_unique": rec_u,
        "recommend": reco
    })

@app.get("/manifest.webmanifest")
def manifest():
    return send_from_directory("static", "manifest.webmanifest", mimetype="application/manifest+json")

@app.get("/sw.js")
def sw():
    return send_from_directory("static", "sw.js", mimetype="text/javascript")
@app.get("/debug/last-html")
def debug_last_html():
    """åªè®€ï¼šæŠŠä¸Šä¸€è¼ªè£œé½Šæ™‚å­˜çš„åŸå§‹ HTML å›çµ¦ä½ æª¢è¦–ï¼ˆæ–¹ä¾¿èª¿æ•´ selectorï¼‰ã€‚"""
    path = os.path.join("data", "last_today.html")
    if not os.path.isfile(path):
        return "No last_today.html yet", 404
    with open(path, "r", encoding="utf-8") as f:
        return f.read(), 200, {"Content-Type": "text/html; charset=utf-8"}

if __name__ == "__main__":
    # åœ¨ Render ä¸Šè«‹æŠŠ Start Command è¨­ç‚ºï¼špython app.py
    app.run(host="0.0.0.0", port=int(os.getenv("PORT", "5000")))
